# -*- coding: utf-8 -*-
"""Projeto Visao - Italo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Oiyx4YLA62iC_2FftUXMs_OUefTYZBOV

---




<center>UNIVERSIDADE FEDERAL DE ALAGOAS </br>
INSTITUTO DE COMPUTAÇÃO </br>
Visão Computacional</br>
<b>Professor: Thales Vieira</br>
Aluno: Italo Rodrigo da Silva Arruda</b></br></center>
</br>

---


Projeto da Disciplina                                   26 de Janeiro de 2021


---
</br>
Instruções:</br>
O projeto deve ser desenvolvidos por grupos de até 2 pessoas (graduação) e individualmente (mestrado).</br>
Preparar uma apresentação de até 10 minutos com slides, e demonstração dos resultados.<br>
Organizar o código em um git para entrega.

# Imports do Projeto
"""

from google.colab import drive
drive.mount('/content/drive');

#Bibliotecas para processamento de imagem
!pip install kornia
import torch
import kornia
import torchvision
import os
import cv2 as cv
import numpy as np
import cv2
import tensorflow as tf
import pickle
from matplotlib import pyplot as plt
from google.colab.patches import cv2_imshow
from PIL import Image

#Instalação do Tesseract
!sudo apt-get install tesseract-ocr tesseract-ocr-por
!sudo apt-get install -y libsm6 libxext6 libxrender-dev
!sudo apt-get install -y poppler-utils
!pip install tesseract -tesseract-por
!pip install textblob
!pip install pytesseract
import pytesseract
print(pytesseract.get_tesseract_version())
print(pytesseract.get_languages())
!pip show pytesseract

#Bibliotecas de Processamento de Linguagem Natural
import nltk
nltk.download("popular")
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd
import re
import string
from nltk.tokenize import word_tokenize
import numpy as np
from numpy.linalg import norm
from nltk.corpus import stopwords
!pip install pyspellchecker
from spellchecker import SpellChecker

"""# Etapa de Visão Computational

## Load Files
"""

Path = '/content/drive/MyDrive/Mestrado/PPGI 2020.2/visao/project/'
myimg = Path + '0-input/img1.jpg'

"""## One Run"""

#Pré-processing

def imagePreProcessing(i):
  img = cv2.imread(Path + '0-input/' + i,0)
  #Equalização do histograma da imagem
  equ = cv2.equalizeHist(img)
  cv2.imwrite(Path + "1-hist/hist_" + i, equ)

  print(Path + "1-hist/hist_" + i)
  print("\n\n")
  res = np.hstack((img,equ))
  
  cv2_imshow(res)

  ret,thresh2 = cv.threshold(img,135,255,cv.THRESH_BINARY_INV) #132
  ret,threshZ = cv.threshold(thresh2,135,255,cv.THRESH_BINARY_INV)
  cv2.imwrite(Path + "2-binary/bin_i_" + i, thresh2)
  print(Path + "2-binary/bin_i_" + i)
  
  res = np.hstack((thresh2,threshZ))
  cv2_imshow(res)

  cv2.imwrite(Path + "3-binary/bin_" + i, threshZ)
  print(Path + "3-binary/bin_" + i)

  imgx = threshZ
  th3 = cv.adaptiveThreshold(imgx,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\
              cv.THRESH_BINARY,11,2)
  cv2.imwrite(Path + "4-threshold/thr_" + i, th3)
  print(Path + "4-threshold/thr_" + i)

  res = np.hstack((threshZ,th3))
  cv2_imshow(res)
  cv2.imwrite('/content/plana.jpg', threshZ)
  return threshZ
#threshZ = imagePreProcessing("img1.jpg")
#cv2_imshow(threshZ)

"""## Graying and Blurring"""

#recebe as imagens, converte para escala de cinza, faz a equalização do histograma
def grayAndBlur():
  myimg = '/content/drive/MyDrive/Mestrado/PPGI 2020.2/visao/projeto/img1.jpg'

  img = cv2.imread(myimg,0)
  equ = cv2.equalizeHist(img)
  res = np.hstack((img,equ)) #stacking images side-by-side
  cv2_imshow(res)
  #cv2.imwrite('res.png',equ)

"""## Contrasting and Filtering"""

#A versão gaussiana leva em consideração a intensidade de pixel dada em relação 
#a uma vizinhança de pixels ao seu redor. Esta etapa produz uma imagem em 
#preto e branco e isola a borda preta da etiqueta em um fundo branco distinto.
def contrastingAndFiltering()
  ret,thresh2 = cv.threshold(img,130,255,cv.THRESH_BINARY_INV)
  ret,threshZ = cv.threshold(thresh2,135,255,cv.THRESH_BINARY_INV)
  res = np.hstack((thresh2,threshZ))
  cv2.imwrite('/content/plana.jpg', threshZ)
  cv2_imshow(res)

"""## Contour Identification"""

def reordernarPontos(points):
    points = points.reshape((4, 2))
    new_points = np.zeros((4, 1, 2), dtype=np.int32)
    add = points.sum(1)
    new_points[0] = points[np.argmin(add)]
    new_points[3] = points[np.argmax(add)]
    diff = np.diff(points, axis=1)
    new_points[1] = points[np.argmin(diff)]
    new_points[2] = points[np.argmax(diff)]
    return new_points

def maiorContornoEncontrar(contours):
    biggest = np.array([])
    max_area = 0
    for i in contours:
        area = cv2.contourArea(i)
        if area > 50:
            peri = cv2.arcLength(i, True)
            approx = cv2.approxPolyDP(i, 0.02 * peri, True)
            if area > max_area and len(approx) == 4:
                biggest = approx
                max_area = area
    return biggest, max_area

#-----------------------------------Processamento de Imagem-----------------------------------

img_path = '/content/drive/MyDrive/Mestrado/PPGI 2020.2/visao/project/0-input/img1.jpg'

#Definindo as dimensões da imagem. Dependendo do tamanho o OCR consegue extrír mais ou menos dados
height = 700 
width = 700 

#lendo uma imagem
img = cv2.imread(img_path)

#Converte para escala de cinza
img_cinza = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)

#Gaussian blur para minimizar o ruído
img_gBlur = cv2.GaussianBlur(img_cinza.copy(), (7, 7), 0) 

#Usando adaptive thresholding
img_binarizada = cv2.adaptiveThreshold( img_gBlur.copy(), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2) 

#Etapa para definir o maior contorno encontrados
img_contornos = img.copy()
img_box = img.copy()

#Desenhando os contornos encontrados
contours, hierarchy = cv2.findContours(img_binarizada, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cv2.drawContours(img_contornos, contours, -1, (0, 255, 0), 3)

#Maior contorno definido
maior_contorno, maxArea = maiorContornoEncontrar(contours)

if maior_contorno.size != 0:
    
    maior_contorno = reordernarPontos(maior_contorno)
    
    # Desenhando o maior contorno
    cv2.drawContours(img_box, maior_contorno, -1, (0, 0, 255), 25)

    # Calculando a matrix de mudança de perspectiva usando os pontos do contorno localizado
    pts1 = np.float32(maior_contorno)
    pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])
    matrix = cv2.getPerspectiveTransform(pts1, pts2)

    # Mudando a perpectiva da imagem com tamanho quadrado
    img_warp_colored = cv2.warpPerspective(img, matrix, (width, height))
    
    # Convertendo a imagem para escala cinza
    img_warp_gray = cv2.cvtColor(img_warp_colored,cv2.COLOR_BGR2GRAY)

    # Aplicando as mesma etapa a imagem já cortada
    img_gBlur = cv2.GaussianBlur(img_warp_gray.copy(), (7, 7), 0)
    img_binarizada = cv2.adaptiveThreshold(
    img_gBlur.copy(), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
    cv2.THRESH_BINARY_INV, 11, 2)
    ret,img_cut = cv.threshold(img_binarizada,135,255,cv.THRESH_BINARY_INV)
else:
    print('Contornos não definidos!')

#-------------------------------Impressões-------------------------------
print(25*"-"+"Imagem de Entrada"+25*"-"+"Imagem Cortada"+25*"-")
print("\n")
cv2_imshow(img)
cv2_imshow(img_warp_colored)

print("\n\n")
print(25*"-"+"Contornos"+25*"-"+"Contornos Maior"+25*"-")
print("\n")
res = np.hstack((img_contornos, img_box))
cv2_imshow(res)

print("\n\n")
print(25*"-"+"Escala de cinza"+25*"-"+"Blur Gaussiano"+25*"-")
print("\n")
res = np.hstack((img_warp_gray,img_gBlur))
cv2_imshow(res)

print("\n\n")
print(25*"-"+"Threshold Adaptativa"+25*"-"+"Imagem Binárizada"+25*"-")
print("\n")    
res = np.hstack((img_binarizada,img_cut))
cv2_imshow(res)

cv2.imwrite("/content/output1.jpg", img_cut)

"""## Extração de Labels"""

#Detect caracteres
def detectarCaractere(img):
  hImg, wImg,_ = img.shape
  cong = r'--oem 3 --psm 11 outputbase digits'
  boxes = pytesseract.image_to_boxes(img)
  for b in boxes.splitlines():
    #print(b)
    b = b.split(' ')
    x,y,w,h = int(b[1]),int(b[2]),int(b[3]),int(b[4])
    cv.rectangle(img,(x,hImg-y),(w,hImg-h),(0,0,255),3)
    cv.putText(img,b[0],(x,hImg-y+25), cv.FONT_HERSHEY_COMPLEX,1,(50,50,255),1)
  cv2_imshow(img)

#Detect Palavra
def detectarPalavra(img):
  n = []
  hImg, wImg,_ = img.shape
  cong = r'--oem 3 --psm 6 outputbase digits'
  #0 2
  #cong = r'--oem 0'
  boxes = pytesseract.image_to_data(img, config=cong, lang='por+eng', nice=2)
  for x,b in enumerate(boxes.splitlines()):
    if x!=0:
      b = b.split()
      #print(b)
      n.append(b)
      if len(b)==12:
        x,y,w,h = int(b[6]),int(b[7]),int(b[8]),int(b[9])
        cv.rectangle(img,(x,y),(w+x,h+y),(0,0,255),2)
        cv.putText(img,b[11],(x,y), cv.FONT_HERSHEY_COMPLEX,0.6,(50,50,255),1)
  cv2_imshow(img)
  return n, img

img_cortada = cv.imread("/content/output1.jpg")
#Retornar a imagem com os labels detectados e um df
df, img_labels = detectarPalavra(img_cortada)

"""# Etapa de Processamento de Linguagem Natural

## Extraíndo texto
"""

import pandas as pd    
import numpy as np   
df_nlp = pd.DataFrame(df)
df_nlp = df_nlp.fillna(value=np.nan)
with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also
    print(df_nlp)

def extrairTexto(df):
  ll = []
  line = " "
  cont = 1
  l = " "
  for i, j, k in zip(df[4], df[10], df[11]):
    if (int(j) != -1):
      l = l + k + " "
      if (int(i) == cont):
        ll.append(k)
        line = line + k + " "
      elif (int(i) <= cont) :
        ll.append("#")
        ll.append(k)
        cont = int(i) 
        print(line)
        line = " "
        line = line + k + " "  
      elif (int(i) >= cont) :
        cont = int(i)
        ll.append("#")
        ll.append(k) 
        print(line)
        line = " "
        line = line + k + " "
  print(l)
  return ll    
linhas = extrairTexto(df_nlp)

corpus = df_nlp.iloc[:, 11:12]
corpus = corpus.dropna()
corpus.columns = ['Text']
corpus.head()

#print(corpus)

"""## Limpeza dos dados"""

#Colocando texto em minusculo
#z = cv.fit_transform(clean_special[:1])
corpus["Text"] = corpus["Text"].str.lower()

#Removendo palavras com numeros
corpus.Text = [re.sub('\w*\d\w*', ' ', s) for s in corpus.Text]

#Removendo pontuação
corpus.Text = ["".join( j for j in i if j not in string.punctuation) for i in  corpus.Text]

print(corpus)

"""## Correção Gramatical"""

spell = SpellChecker('pt', distance=1)
spell.word_frequency.load_words(['valor energético', 'carboidratos', 'proteínas', 'gorduras totais', 'gorduras'
                                 'gorduras saturadas', 'gorduras trans', 'gorduras monoinsaturadas', 
                                 'gorduras polinsaturades', 'colesterol', 'fibra alimentar', 'sódio', 
                                 'cálcio', 'vitamina a', 'vitamina b12', 'vitamina c', 'energético', 'polinsaturades'])
# Encontrar palavras com a ortográfia errada
misspelled = spell.unknown(corpus.Text)

for word in misspelled:
    # Get the one `most likely` answer
    print(spell.correction(word))

    # Get a list of `likely` options
    #print(spell.candidates(word))

misspelled
print(corpus.Text)

"""## A saída dos textos seriam mapeados num aplicativo para sugerir campos e alterar dados que foram extraídos de forma imprecisa. (Trabalhos Futuros)"""